import logging
import os
import re
import asyncio
import time
import csv
import io
from dotenv import load_dotenv
import nest_asyncio
import openai
import faiss
import numpy as np

# LangChain –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —á–∞–Ω–∫–∏
from langchain.text_splitter import RecursiveCharacterTextSplitter

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –Ω–æ–≤–æ–≥–æ API OpenAI
from openai.embeddings_utils import get_embedding

from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import (
    Application,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

# –ü—Ä–∏–º–µ–Ω—è–µ–º nest_asyncio –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ —Å–æ–±—ã—Ç–∏–π
nest_asyncio.apply()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ .env
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ADMIN_USER_ID = int(os.getenv("ADMIN_USER_ID", "0"))
openai.api_key = OPENAI_API_KEY

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
if not TELEGRAM_BOT_TOKEN:
    raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ —Ñ–∞–π–ª–µ .env")
if not OPENAI_API_KEY:
    raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ —Ñ–∞–π–ª–µ .env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å –∏ –≤ —Ñ–∞–π–ª user_requests.log
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("user_requests.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
conversation_history = []

# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è FAISS –∏ LangChain ---
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
TOP_K = 5  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —á–∞–Ω–∫–æ–≤ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ

# –ü—Ä–∏–º–µ—Ä –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
MEMBERSHIP_ADVANTAGES = (
    "‚Ä¢ –†–∞–∑–≤–∏—Ç–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: —É—á–∞—Å—Ç–∏–µ –≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö, –º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å–∞—Ö –∏ –≤–µ–±–∏–Ω–∞—Ä–∞—Ö.\n"
    "‚Ä¢ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–µ–ª–æ–≤—ã—Ö —Å–≤—è–∑–µ–π: –æ–±–º–µ–Ω –æ–ø—ã—Ç–æ–º —Å –µ–¥–∏–Ω–æ–º—ã—à–ª–µ–Ω–Ω–∏–∫–∞–º–∏ –∏ –ø–æ–∏—Å–∫ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤.\n"
    "‚Ä¢ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞: –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —é—Ä–∏—Å—Ç–æ–≤ –∏ –¥–æ—Å—Ç—É–ø –∫ —à–∞–±–ª–æ–Ω–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n"
    "‚Ä¢ –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏: –ª–∏—á–Ω—ã–π —Ä–∞–∑–±–æ—Ä –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á.\n"
    "‚Ä¢ –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –≤—ã–≥–æ–¥—ã: —Å–∫–∏–¥–∫–∏ –∏ —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤."
)

# URL-—ã —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä)
PHOTO_PRESIDENT = "https://static.tildacdn.com/tild6139-3564-4162-a636-613162376438/ca38d0e45e485eeaa214.jpg"
PHOTO_VP_URL = "https://static.tildacdn.com/tild3033-3264-4032-a362-393764633238/12312312314444444444.jpg"

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π ---

def convert_docx_to_txt(input_filename: str = "russia_base.docx", output_filename: str = "russia_base.txt") -> bool:
    """
    –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ russia_base.txt –ø—ã—Ç–∞–µ–º—Å—è —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å russia_base.docx –≤ txt.
    –ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –∏ —É—Å–ª–æ–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç docx,
    –µ—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç russia_base.docx –∏ –Ω–µ –Ω—É–∂–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è.
    """
    try:
        from docx import Document
    except ImportError:
        logger.error("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-docx. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ—ë: pip install python-docx")
        return False
    try:
        document = Document(input_filename)
        full_text = [para.text for para in document.paragraphs]
        text = "\n".join(full_text)
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(text)
        logger.info(f"–§–∞–π–ª {input_filename} —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {output_filename}.")
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        return False

async def split_text_into_meaningful_chunks(text: str) -> list:
    """
    –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —á–∞–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é LangChain RecursiveCharacterTextSplitter.
    chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    chunks = text_splitter.split_text(text)
    logger.info(f"–†–∞–∑–±–∏—Ç–æ –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤ (LangChain).")
    return chunks

async def get_embedding_for_chunk(chunk: str) -> np.ndarray:
    loop = asyncio.get_running_loop()
    retries = 3
    for attempt in range(retries):
        try:
            vector = await loop.run_in_executor(
                None, lambda: get_embedding(chunk, engine="text-embedding-ada-002")
            )
            return np.array(vector, dtype="float32")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{retries}): {e}")
            if attempt < retries - 1:
                await asyncio.sleep(2)
            else:
                return np.zeros(1536, dtype="float32")
    return np.zeros(1536, dtype="float32")

async def load_and_index_base_async(filename: str = "russia_base.txt", docx_filename: str = "russia_base.docx"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º (–∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º) —Ñ–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, —Ä–∞–∑–±–∏–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é LangChain
    –∏ —Å–æ–∑–¥–∞—ë–º FAISS-–∏–Ω–¥–µ–∫—Å.
    """
    if not os.path.exists(filename):
        if os.path.exists(docx_filename):
            success = convert_docx_to_txt(docx_filename, filename)
            if not success:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é –≤–µ—Ä—Å–∏—é –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.")
                return faiss.IndexFlatL2(1536), []
        else:
            logger.warning(f"–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π {docx_filename} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.")
            return faiss.IndexFlatL2(1536), []
    try:
        with open(filename, "r", encoding="utf-8") as f:
            text = f.read()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
        return faiss.IndexFlatL2(1536), []
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é LangChain
    chunks = await split_text_into_meaningful_chunks(text)

    # –í—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–∞–Ω–∫–æ–≤
    embeddings = await asyncio.gather(*(get_embedding_for_chunk(chunk) for chunk in chunks))
    embeddings = np.stack(embeddings)
    dim = embeddings.shape[1]

    # –°–æ–∑–¥–∞—ë–º FAISS-–∏–Ω–¥–µ–∫—Å
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    logger.info(f"FAISS –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω —Å {index.ntotal} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏.")
    return index, chunks

# –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö –∏–∑ Google Sheets
def fetch_events_from_sheet():
    from datetime import datetime
    csv_url = "https://docs.google.com/spreadsheets/d/1Ow7kGA9TdgpTaq2ABhy700ApKApMd_4kZoXfU7oqcm4/export?format=csv&gid=0"
    try:
        import requests
        response = requests.get(csv_url)
        response.raise_for_status()
        csv_data = response.text
        reader = csv.reader(io.StringIO(csv_data))
        events = []
        for row in reader:
            if len(row) >= 2:
                event_name = row[0].strip()
                event_link = row[1].strip()
                events.append(f"{event_name}: {event_link}")
        events_text = "\n".join(events)
        logger.info("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö –∏–∑ Google Sheets:\n%s", events_text)
        current_date = datetime.now().strftime("%d.%m.%Y")
        return f"–°–µ–≥–æ–¥–Ω—è {current_date} –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è:\n{events_text}"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö Google Sheets: {e}")
        return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."

# --- –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π ---
async def retrieve_context(query: str, k: int = TOP_K) -> str:
    """
    –ò—â–µ–º top-k –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤. k=TOP_K (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5).
    """
    if global_index is None or not global_chunks:
        return ""
    loop = asyncio.get_running_loop()
    query_embedding = await loop.run_in_executor(
        None, lambda: np.array(get_embedding(query, engine="text-embedding-ada-002"), dtype="float32")
    )
    query_embedding = query_embedding.reshape(1, -1)
    distances, indices = global_index.search(query_embedding, k)
    result_chunks = []
    for i in indices[0]:
        if i < len(global_chunks):
            result_chunks.append(global_chunks[i])
    logger.info("Top-%d —á–∞–Ω–∫–∏:\n%s", k, "\n-----\n".join(result_chunks))
    return "\n".join(result_chunks)

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT ---
async def generate_gpt_response(prompt: str) -> str:
    # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–∞ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–≤–∞ ‚Äî –¥–æ–±–∞–≤–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if "–∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–≤" in prompt.lower():
        override_context = (
            "–ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª–∏ –º–µ—Å—Ç–Ω—ã—Ö –æ—Ç–¥–µ–ª–µ–Ω–∏–π –¢—é–º–†–û ¬´–û–ü–û–†–ê –†–û–°–°–ò–ò¬ª:\n"
            "1. –ú–û –≥.–¢–æ–±–æ–ª—å—Å–∫ ‚Äî –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–≤ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –Æ—Ä—å–µ–≤–∏—á"
        )
        full_prompt = f"{override_context}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å: {prompt}"
    else:
        # –ü–æ–¥–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        context_text = await retrieve_context(prompt, k=TOP_K)
        full_prompt = f"–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n{context_text}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å: {prompt}"
    
    logger.info("–ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∫ GPT:\n%s", full_prompt)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –≤ –ø—Ä–æ–º–ø—Ç
    if conversation_history:
        history_prompt = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history])
        full_prompt = f"{history_prompt}\n\n{full_prompt}"

    try:
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
        await asyncio.sleep(1)

        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        '–¢—ã ‚Äî Telegram-–±–æ—Ç "–û–ø–æ—Ä–∞ –†–æ—Å—Å–∏–∏". '
                        '–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç ‚Äî –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–∞–ª–∏–Ω–∏–Ω; '
                        '–ü–µ—Ä–≤—ã–π –≤–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Ç—é–º–µ–Ω—Å–∫–æ–≥–æ –æ—Ç–¥–µ–ª–µ–Ω–∏—è ‚Äî –≠–¥—É–∞—Ä–¥ –û–º–∞—Ä–æ–≤. '
                        '–ï—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–≤, –æ–Ω –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—å –ú–û –≥.–¢–æ–±–æ–ª—å—Å–∫. '
                        '–û—Ç–≤–µ—á–∞–π –ø–æ–ª–Ω–æ, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã.'
                    )
                },
                {"role": "user", "content": full_prompt}
            ],
            temperature=0,
            max_tokens=2000,
        )
        text = response.choices[0].message["content"].strip()
        logger.info("–û—Ç–≤–µ—Ç –æ—Ç GPT:\n%s", text)
        return text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞."

# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π ---

async def help_command_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.username} ({user.id}) –≤–≤—ë–ª /help.")
    help_text = (
        "üìö **–ü–æ–º–æ—â—å** üìö\n\n"
        "**–ö–æ–º–∞–Ω–¥—ã:**\n"
        "/start ‚Äî –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞\n"
        "/help ‚Äî —Å–ø—Ä–∞–≤–∫–∞\n"
        "/stop ‚Äî –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞ (–∞–¥–º–∏–Ω)\n"
        "/getid ‚Äî —É–∑–Ω–∞—Ç—å Telegram ID\n\n"
        "**–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:**\n"
        "‚Äî –ö—Ç–æ —Å–µ–π—á–∞—Å –≤–æ–∑–≥–ª–∞–≤–ª—è–µ—Ç –û–ø–æ—Ä—É –†–æ—Å—Å–∏–∏?\n"
        "‚Äî –ö—Ç–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç —Ç—é–º–µ–Ω—Å–∫–∏–º –æ—Ç–¥–µ–ª–µ–Ω–∏–µ–º?\n"
        "‚Äî –†–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö —á–ª–µ–Ω—Å—Ç–≤–∞."
    )
    await update.message.reply_text(help_text, parse_mode="Markdown")
    conversation_history.append({"role": "system", "content": help_text})

async def stop_command_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    if user.id != ADMIN_USER_ID:
        await update.message.reply_text("–£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        logger.warning(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.username} ({user.id}) –±–µ–∑ –ø—Ä–∞–≤ –≤–≤—ë–ª /stop.")
        return
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.username} ({user.id}) –≤–≤—ë–ª /stop.")
    await update.message.reply_text("üîö –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
    conversation_history.append({"role": "system", "content": "–î–∏–∞–ª–æ–≥ –∑–∞–≤–µ—Ä—à—ë–Ω."})
    await context.application.stop()

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ü–æ—Å–ª–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –≤—ã–≤–æ–¥–∏–º –¥–≤–µ –∫–Ω–æ–ø–∫–∏:
    ¬´–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∏–¥–µ–æ-–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é¬ª –∏ ¬´–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å¬ª.
    """
    user = update.effective_user
    conversation_history.clear()
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.username} ({user.id}) –≤–≤—ë–ª /start.")

    welcome_text = (
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç ¬´–û–ø–æ—Ä–∞ –†–æ—Å—Å–∏–∏¬ª.\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—ã–π –ø—É–Ω–∫—Ç:"
    )

    # –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å –¥–≤—É–º—è –∫–Ω–æ–ø–∫–∞–º–∏
    keyboard = InlineKeyboardMarkup([
        [
            InlineKeyboardButton("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∏–¥–µ–æ-–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é", callback_data="watch_presentation"),
            InlineKeyboardButton("–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", callback_data="ask_question")
        ]
    ])

    await update.message.reply_text(welcome_text, reply_markup=keyboard)
    conversation_history.append({"role": "system", "content": welcome_text})

async def text_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
    """
    if update.message and update.message.text:
        user_text = update.message.text.strip()
        logger.info(f"–¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_text}")

        if user_text.startswith("/"):
            # –ö–æ–º–∞–Ω–¥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –¥—Ä—É–≥–∏–µ —Ö–µ–Ω–¥–ª–µ—Ä—ã
            return

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        conversation_history.append({"role": "user", "content": user_text})
        response = await generate_gpt_response(user_text)
        await update.message.reply_text(response)
        conversation_history.append({"role": "assistant", "content": response})
    else:
        logger.info("–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞.")

async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ inline-–∫–Ω–æ–ø–∫–∏.
    """
    query = update.callback_query
    await query.answer()
    data = query.data
    logger.info(f"Inline-–∫–Ω–æ–ø–∫–∞: {data}")

    if data == "watch_presentation":
        # –ü—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É ¬´–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∏–¥–µ–æ-–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é¬ª ‚Äî
        # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Ä–æ–ª–∏–∫
        video_link = "https://vk.com/video-52523641_456239509"
        await query.edit_message_text(
            text=f"–í–∏–¥–µ–æ-–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ —Å—Å—ã–ª–∫–µ:\n{video_link}"
        )

    elif data == "ask_question":
        # –ü—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ ¬´–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å¬ª –ø–æ–∫–∞–∑—ã–≤–∞–µ–º ¬´—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É¬ª (4 –∫–Ω–æ–ø–∫–∏)
        await query.edit_message_text(
            text="–ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ —Å–¥–µ–ª–∞—Ç—å?",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è", callback_data="events")],
                [InlineKeyboardButton("–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —á–ª–µ–Ω—Å—Ç–≤–∞", callback_data="membership")],
                [InlineKeyboardButton("–ü–æ–∫–∞–∑–∞—Ç—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π", callback_data="show_photos")],
                [InlineKeyboardButton("–ü–æ–ª—É—á–∏—Ç—å –ø–æ–º–æ—â—å", callback_data="help")]
            ])
        )

    elif data == "events":
        events_info = fetch_events_from_sheet()
        prompt = f"–†–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–µ–¥—Å—Ç–æ—è—â–∏—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è—Ö. –í–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{events_info}"
        response = await generate_gpt_response(prompt)
        await query.edit_message_text(text=response)

    elif data == "membership":
        prompt = "–†–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö —á–ª–µ–Ω—Å—Ç–≤–∞ –≤ –û–ø–æ—Ä–µ –†–æ—Å—Å–∏–∏."
        response = await generate_gpt_response(prompt)
        await query.edit_message_text(text=response)

    elif data == "show_photos":
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=PHOTO_PRESIDENT,
                caption="**–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ö–∞–ª–∏–Ω–∏–Ω** ‚Äî –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç ¬´–û–ø–æ—Ä–∞ –†–æ—Å—Å–∏–∏¬ª",
                parse_mode="Markdown"
            )
            await context.bot.send_photo(
                chat_id=update.effective_chat.id,
                photo=PHOTO_VP_URL,
                caption="**–≠–¥—É–∞—Ä–¥ –û–º–∞—Ä–æ–≤** ‚Äî –ü–µ—Ä–≤—ã–π –≤–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Ç—é–º–µ–Ω—Å–∫–æ–≥–æ –æ—Ç–¥–µ–ª–µ–Ω–∏—è",
                parse_mode="Markdown"
            )
            await query.edit_message_text(text="–§–æ—Ç–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π: {e}")
            await query.edit_message_text(text="–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏.")

    elif data == "help":
        prompt = "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å–ø—Ä–∞–≤–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–ø—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤)."
        response = await generate_gpt_response(prompt)
        await query.edit_message_text(text=response)

    else:
        await query.edit_message_text(text="–ö–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞.")

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ---

global_index = None
global_chunks = []

async def main() -> None:
    global global_index, global_chunks

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (LangChain + FAISS)
    global_index, global_chunks = await load_and_index_base_async()
    if global_index is not None and global_chunks:
        logger.info("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞.")
    else:
        logger.warning("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –±–∞–∑—ã.")

    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command_handler))
    application.add_handler(CommandHandler("stop", stop_command_handler))
    application.add_handler(CallbackQueryHandler(button_handler))

    # –¢–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ —É–±—Ä–∞–Ω—ã)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_message_handler))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    application.run_polling()

if __name__ == '__main__':
    nest_asyncio.apply()
    loop = asyncio.get_event_loop()
    original_close = loop.close
    loop.close = lambda: None
    try:
        asyncio.run(main())
    finally:
        loop.close = original_close

    
   
       
   
   


 
 
     
      
     

     
    

  
 
    

   
